 <!-- Written, maintained and owned by Louis Moser, Linus Braun, Benjamin Keppler (MURI DEVELOPMENT TEAM) -->

# MURI Projekt - Dokumentations-Grundger√ºst

**Projektversion**: 2.0.0  
**Datum**: Dezember 2025  
**Status**: In Entwicklung

---

## Inhaltsverzeichnis

1. [Projektplan](#projektplan)
2. [Software-Architektur](#software-architektur)
3. [Designentscheidungen](#designentscheidungen)
4. [Technische Herleitungen](#technische-herleitungen)
5. [Lessons Learned](#Lessons-Learned)
5. [Documente und Referenzen](#Dokumente-und-Referenzen)

---

## Zugeh√∂rige Projektdokumentationen
[logic_2.md](logic_2)  
[ros.md](ros.md)  
[config.py](../muri_logics/config.py)  


---

# Projektplan

## 1. Projekt√ºbersicht

### 1.1 Ziele
- Entwicklung eines autonomen mobilen Roboters MURI (Mechanische Untergrund Ratte f√ºr Inspektionen) zur Navigation und Objektverfolgung
- Implementierung einer hierarchischen State-Machine-basierte Steuerungslogik
- Integration mit ROS2 f√ºr Echtzeitf√§higkeit und Modularit√§t
- Unterst√ºtzung f√ºr Kamera-basierte Zielerfassung und Aruco-Marker-Verfolgung

### 1.2 Projektumfang
- **Kernkomponenten**: 5 Logik-Module (Init, Drive, Turn, Follow, MainController)
- **Vision-Systeme**: Bild-Verarbeitung, Aruco-Marker-Erkennung
- **ROS2-Integration**: Action Server f√ºr alle Module
- **Dokumentation**: Design-Spezifikationen, Testpl√§ne, Deployment-Guides

### 1.3 Stakeholder
- Entwicklungsteam 
    - Braun Linus
    - Keppler Benjamin
    - Moser Louis

- Auftraggeber
    - Prof. Dr. Mathias Lorenzen

---

## 2. Meilensteine und Zeitplan

### Phase 1: Projektinitialisierung & Planung (KW43-KW44/2025)
| Meilenstein | Termin | Status | Beschreibung |
|------------|--------|--------|------------|
| M1.1 | KW43 (23.10.25) | ‚úÖ | Einarbeitung ROS2 abgeschlossen, Roboter √ºber ROS ansprechbar |
| M1.2 | KW44 (30.10.25) | ‚úÖ | Projektplan/Projektarchitektur erstellt und abgestimmt |

### Phase 2: Repository-Setup & Architektur (KW45/2025)
| Meilenstein | Termin | Status | Beschreibung |
|------------|--------|--------|------------|
| M2.1 | KW45 (06.11.25) | ‚úÖ | Repository initialisiert, Ordner- und Dateistruktur entsprechend Softwarearchitektur aufgesetzt |

### Phase 3: Basis-Fahrfunktionalit√§t (KW46-KW47/2025)
| Meilenstein | Termin | Status | Beschreibung |
|------------|--------|--------|------------|
| M3.1 | KW47 (20.11.25) | ‚úÖ | Allgemeine Fahrfunktionalit√§t implementiert (Geschwindigkeitssteuerung, Lageregelung) |
| M3.2 | KW48 (27.11.25) | ‚úÖ | Unit-Tests und Debugging f√ºr Basis-Fahrfunktionalit√§t abgeschlossen |

### Phase 4: ArUco-Erkennung & Folgeman√∂ver (KW49-KW51/2025)
| Meilenstein | Termin | Status | Beschreibung |
|------------|--------|--------|------------|
| M4.1 | KW49 (04.12.25) | ‚úÖ | ArUco-ID-Unterscheidung und Robotererkennung implementiert |
| M4.2 | KW51 (18.12.25) | ‚úÖ | Folgeman√∂ver-Code vollst√§ndig implementiert und integriert |
| M4.3 | KW52 (23.12.25) | ‚úÖ | Testing und Debugging f√ºr Folgeman√∂ver |

### Phase 5: Finalisierung & Dokumentation (KW1-KW3/2026)
| Meilenstein | Termin | Status | Beschreibung |
|------------|--------|--------|------------|
| M5.1 | KW2 (02.01.26) | ‚úÖ | Restliche Tests abgeschlossen, alle funktionalen Anforderungen validiert |
| M5.2 | KW3 (21.01.26) | ‚è≥ | Gesamtdokumentation finalisiert (Projektplan, Architektur, technische Herleitungen, Systemauswertung) |
| M5.3 | KW3 (21.01.26) | ‚úÖ | Build-/Install-Anleitung erstellt |
| M5.4 | KW3 (21.01.26) | üéØ | **Abschlusspr√§sentation und finale Abgabe** |

---

**Legende:**
- ‚úÖ Abgeschlossen (100%)
- ‚ö†Ô∏è In Arbeit mit Verz√∂gerung
- ‚è≥ Geplant/In Bearbeitung
- üéØ Kritischer Meilenstein (Deadline)

---

## 3. Geplante Aktualisierungen & Fehlerbehandlung

### 3.1 Fehler (Priorit√§t: P1)
| Fehler | Modul | Auswirkung | Status | Zielversion |
|--------|-------|-----------|--------|------------|

### 3.2 Feature-Enhancements (Priorit√§t: P2)
| Feature | Beschreibung | Abh√§ngigkeiten | Status | Zielversion |
|---------|-------------|-----------------|--------|------------|
| Pause-Mechanismus | Vollst√§ndige Implementierung von PAUSE-State | M3.1 | ‚è≥ Geplant | v2.1.0 |
| Error-Recovery | Automatische Fehlerbehandlung & Retry-Logik | M4.1 | ‚è≥ Geplant | v2.1.0 |
| Dynamic-Tuning | Runtime-Anpassung von Regelparametern | M4.2 | ‚è≥ Geplant | v2.2.0 |
| Logging-System | Strukturiertes Logging statt print() | M5.1 | ‚è≥ Geplant | v2.1.0 |

### 3.3 Bekannte Limitierungen
- **FollowLogic**: Nur ein Marker gleichzeitig verfolgbar
- **DriveLogic**: Keine Kollisionserkennung (ralativ)
- **MainController**: PAUSE-Zustand nicht persistent
- **Allgemein**: Keine Multi-Robot-Koordination

### 3.4 Abh√§ngigkeiten & Versioning

```
MURI v2.0.0 (Current)
‚îú‚îÄ‚îÄ ROS2 Humble (min: Iron)
‚îú‚îÄ‚îÄ Python 3.9+ (min: 3.8)
‚îú‚îÄ‚îÄ OpenCV 4.5+ (f√ºr Vision)
‚îú‚îÄ‚îÄ numpy 1.20+
‚îî‚îÄ‚îÄ pytest (f√ºr Unit-Tests)

MURI v2.0.1 (Hotfix - geplant)
‚îú‚îÄ‚îÄ TurnLogic Key-Fix
‚îú‚îÄ‚îÄ Method-Name Konsistenz
‚îî‚îÄ‚îÄ State-Name Harmonisierung

MURI v2.1.0 (Feature-Release - geplant)
‚îú‚îÄ‚îÄ Pause-Mechanism
‚îú‚îÄ‚îÄ Logging-System
‚îú ‚îÄ‚îÄ Error-Recovery
‚îî‚îÄ‚îÄ Documentation Updates
```

---

# Software-Architektur

## 1. Architektur-√úbersicht

![Softweare Architektur √úbersicht](<softweare_architektur.png>)

### 1.1 Schichtmodell

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   ROS2 Interface Layer                  ‚îÇ
‚îÇ    (Action Servers, Topics, Services)                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ            High-Level Control Layer                     ‚îÇ
‚îÇ         (MainController State Machine)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ          Behavior Logic Layer                           ‚îÇ
‚îÇ  (InitLogic, DriveLogic, TurnLogic, FollowLogic)        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ            Foundation Layer                             ‚îÇ
‚îÇ   (Interfaces, Common Functions, Configuration)         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ            Hardware Abstraction Layer                   ‚îÇ
‚îÇ    (Sensors, Odometry, Motors, Camera)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 Modularer Aufbau

```
muri_logics/
‚îú‚îÄ‚îÄ logic_interface.py          # Basis-Interfaces
‚îú‚îÄ‚îÄ general_funcs.py            # Gemeinsame Funktionen
‚îú‚îÄ‚îÄ config.py                   # Konfigurationsparameter
‚îú‚îÄ‚îÄ init_logic.py               # InitLogic-Modul
‚îú‚îÄ‚îÄ drive_logic.py              # DriveLogic-Modul
‚îú‚îÄ‚îÄ turn_logic.py               # TurnLogic-Modul
‚îú‚îÄ‚îÄ follow_logic.py             # FollowLogic-Modul
‚îî‚îÄ‚îÄ main_controller.py          # MainController
```

---

## 2. Komponentenbeschreibung

### 2.1 Logic Interface Layer

**Datei**: `logic_interface.py`

```python
# Base Classes
class Out(ABC):
    """Abstrakte Output-Klasse"""
    - values: Dict[str, float]
    - isValid: bool
    - resetOut()
    - getError()
    
class LogicInterface(ABC):
    """Standard Interface f√ºr Logic-Module"""
    - getOut() ‚Üí Out
    - setActive() ‚Üí bool
    - state_machine()
    - getActiveState() ‚Üí Enum
    - reset()
    - setOdomData(x, y, t)
    - setCameraData(angle, distance)
    
class ExtendedLogicInterface(LogicInterface):
    """Erweiterte Interface mit Aruco-Support"""
    - setArucoData(id)
```

**Designentscheidung**: 
- Abstract Base Classes f√ºr Konsistenz
- Klare Trennung von Input/Output
- Erweiterbar ohne Bruch der API

### 2.2 Behavior Logic Modules

#### InitLogic
- **Verantwortung**: Initiale Ausrichtung zum Ziel
- **State-Count**: 6 States
- **Ausgaben**: angular_velocity_z, turned_angle
- **Abh√§ngigkeiten**: p_regulator, quaternion_to_yaw

#### DriveLogic
- **Verantwortung**: Vorw√§rtsbewegung mit Ausrichtungskontrolle
- **State-Count**: 6 States
- **Ausgaben**: linear_velocity_x, angular_velocity_z, distance_remaining
- **Abh√§ngigkeiten**: p_regulator, quaternion_to_yaw, Schpieth-Parameter

#### TurnLogic
- **Verantwortung**: Drehman√∂ver zur Neuausrichtung
- **State-Count**: 6 States
- **Ausgaben**: angular_velocity_z, turned_angle
- **Abh√§ngigkeiten**: p_regulator, quaternion_to_yaw

#### FollowLogic
- **Verantwortung**: Verfolgung eines Markers
- **State-Count**: 7 States (mit ABORT)
- **Ausgaben**: linear_velocity_x, angular_velocity_z, distance_remaining
- **Abh√§ngigkeiten**: p_regulator, quaternion_to_yaw, Aruco-Daten

### 2.3 MainController

**Verantwortung**: 
- High-Level Orchestration
- State-Transitions zwischen Modulen
- Zielmanagement
- Aruco-Trigger-Logik

**State-Graph**:
```
INIT ‚Üí IDLE ‚Üí INIT_ROBOT ‚Üí DRIVE ‚Üî TURN
                              ‚Üì
                           FOLLOW 
                              ‚îî‚îÄ‚îÄ‚Üí (zur√ºck zu DRIVE)
```

---

## 3. Schnittstellen-Spezifikation

### 3.1 Input-Schnittstellen

| Schnittstelle | Typ | Einheit | Quelle | Update-Rate |
|---------------|-----|---------|--------|------------|
| `/odom` | pose (x, y, Œ∏) | m, rad | Odometrie | 100 Hz |
| `/camera_data` | (angle, distance) | rad, m | Vision | 30 Hz |
| `/aruco_markers` | marker_id | int | Vision | 30 Hz |
| `setOdomData()` | (x, y, t) | m, rad | ROS-Topic | - |
| `setCameraData()` | (angle, distance) | rad, m | ROS-Topic | - |
| `setArucoData()` | id | int | ROS-Topic | - |

### 3.2 Output-Schnittstellen

| Schnittstelle | Typ | Einheit | Ziel | Frequenz |
|---------------|-----|---------|------|----------|
| `/cmd_vel` | (linear_x, angular_z) | m/s, rad/s | Motor-Controller | 100 Hz |
| `getOut()` | Out-Objekt | - | Action-Server | On-Demand |
| `values['linear_velocity_x']` | float | m/s | Cmd-Vel | - |
| `values['angular_velocity_z']` | float | rad/s | Cmd-Vel | - |

---

## 4. Datenfluss und Timing

### 4.1 Kontrollschleife

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ROS2 Timer (100 Hz)                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Sensor-Daten einlesen                        ‚îÇ
‚îÇ    ‚îî‚îÄ /odom ‚Üí setOdomData()                     ‚îÇ
‚îÇ    ‚îî‚îÄ /camera ‚Üí setCameraData()                 ‚îÇ
‚îÇ    ‚îî‚îÄ /aruco ‚Üí setArucoData()                   ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ 2. State-Machine ausf√ºhren                      ‚îÇ
‚îÇ    ‚îî‚îÄ MainController.state_machine()            ‚îÇ
‚îÇ    ‚îî‚îÄ Aktives Modul.state_machine()             ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ 3. Berechnung durchf√ºhren                       ‚îÇ
‚îÇ    ‚îî‚îÄ Aktives Modul.calculate()                 ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ 4. Output publishen                             ‚îÇ
‚îÇ    ‚îî‚îÄ /cmd_vel ‚Üê linear_velocity_x, angular_z  ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ 5. Feedback senden                              ‚îÇ
‚îÇ    ‚îî‚îÄ Action-Feedback aktualisieren             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

# Designentscheidungen

## 1. State Machine Pattern

### 1.1 Warum State Machines?

**Entscheidung**: Verwendung des State Machine Patterns f√ºr alle Logik-Module

**Begr√ºndung**:
1. **Determinismus**: Vorhersagbares Verhalten, klare Zustands√ºberg√§nge
2. **Debugging**: Einfaches Tracking des aktuellen Zustands
3. **Testing**: Isolierbare States, leicht zu testen
4. **Wartbarkeit**: Logische Struktur, einfach erweiterbar
5. **Fehlerbehandlung**: SUCCESS/FAILED-States f√ºr klare Ausnahmef√§lle

**Alternativen betrachtet**:
- Behavior Trees: ‚ùå Zu komplex f√ºr diesen Anwendungsfall
- FSM mit Events: ‚ùå ROS2 hat keine Event-Systeme
- Hierarchische FSM: ‚úÖ √Ñhnlich gew√§hlt (MainController + Sub-Module)

### 1.2 State-Struktur

Alle Module verwenden 6 Standard-States:
```
INIT ‚Üí IDLE ‚Üí READY ‚Üí *MOVE ‚Üí SUCCESS/FAILED
```

**Warum diese Struktur?**
- `INIT`: Ressourcen-Initialisierung
- `IDLE`: Bereitschaftszustand, spart Rechenzeit
- `READY`: Konfiguration vor Aktivit√§t
- `*MOVE`: Aktive Kontrolle
- `SUCCESS/FAILED`: Abschlusszust√§nde mit klarer Aussagekraft

---

## 2. Proportional-Regler (P-Regler)

### 2.1 Warum P-Regler und nicht PID?

**Entscheidung**: Verwendung eines einfachen P-Reglers statt PID

**Begr√ºndung**:
1. **Einfachheit**: Weniger Parameter zu tunen
2. **Robustheit**: Weniger √úberschwinger bei schnellen √Ñnderungen
3. **Reaktionsgeschwindigkeit**: F√ºr diese Anwendung ausreichend
4. **Recheneffizienz**: Keine Integration/Differentiation n√∂tig
5. **Stabilit√§t**: In der Praxis stabil ohne I/D-Anteile

**Herleitung**:
```
Error = Sollwert - Ist-Wert
Output = -Kp * Error

Beispiel (Winkelfehler):
Error = angle_to_target
Kp = 1.0
Output = -1.0 * Error

Wenn Error = 0.5 rad (28¬∞):
Output = -0.5 rad/s (dreht gegen Error)
```

**S√§ttigung**:
```python
output = max(-max_vel, min(output, max_vel))
# Verhindert √úbersteuerung
```

---

## 3. Hierarchische Steuerungsarchitektur

### 3.1 Warum Hierarchie?

**Entscheidung**: MainController orchestriert Sub-Module statt flache Struktur

**Begr√ºndung**:
1. **Separation of Concerns**: Jedes Modul hat klare Verantwortung
2. **Wiederverwendbarkeit**: Modules k√∂nnen einzeln getestet werden
3. **Skalierbarkeit**: Neue Verhalten ohne √Ñnderung bestehender Module
4. **Fehlertoleranz**: Isolation von Fehlern auf Modul-Ebene

**Struktur**:
```
MainController (Orchestrator)
‚îú‚îÄ InitLogic (Initialisierung)
‚îú‚îÄ DriveLogic (Navigation)
‚îú‚îÄ TurnLogic (Rotation)
‚îî‚îÄ FollowLogic (Verfolgung)
```

### 3.2 Alternativarchitekturen betrachtet

| Ansatz | Vor | Nachteil | Entscheidung |
|--------|-----|---------|------------|
| **Monolith** | Einfach | Schwer zu debuggen | ‚ùå |
| **Flache Module** | Modular | Schwer zu koordinieren | ‚ùå |
| **Hierarchisch** | Klar strukturiert | Etwas Overhead | ‚úÖ |
| **Actor Model** | Robust | ROS2 Hat keine Actor-Libs | ‚ùå |

---

## 4. Aruco-Marker Integration

### 4.1 Warum Aruco-Marker?

**Entscheidung**: Verwendung von Aruco-Markern f√ºr Objektverfolgung

**Begr√ºndung**:
1. **Robustheit**: Funktioniert unter verschiedenen Lichtsituationen
2. **Eindeutigkeit**: Jeder Marker hat eindeutige ID
3. **Performance**: Schnell zu erkennen (OpenCV optimiert)
4. **Standardisiert**: IEEE-Standard, weit verbreitet
5. **Kosteneffizient**: Einfach druckbar
---

## 5. DriveLogic Schpieth-Parameter

### 5.1 Warum separater Geschwindigkeit-Parameter?

**Entscheidung**: `__schpieth` statt fest kodierte Geschwindigkeit

**Begr√ºndung**:
1. **Flexibilit√§t**: Fahrtgeschwindigkeit zur Laufzeit anpassen
2. **Sicherheit**: Langsamer fahren in kritischen Situationen
3. **Optimierung**: Schneller fahren auf freien Fl√§chen
4. **Testbarkeit**: Verschiedene Geschwindigkeiten einfach testen
---

## 6. FollowLogic Abstands-P-Regler

### 6.1 Warum Negation im Fehler?

**Code**:
```python
linear_velocity = p_regulator(
    -(distance - follow_distance),  # Negation!
    KP_FOLLOW_LINEAR,
    MAX_VELOCITY
)
```

**Begr√ºndung**:
```
Ohne Negation:
- Soll: 0.2 m (follow_distance)
- Ist: 0.5 m (distance)
- Error = 0.5 - 0.2 = +0.3
- Output = -Kp * 0.3 = negativ ‚Üí f√§hrt r√ºckw√§rts ‚ùå

Mit Negation:
- Error = -(0.5 - 0.2) = -0.3
- Output = -Kp * (-0.3) = positiv ‚Üí f√§hrt vorw√§rts ‚úÖ
```

**Intuitive Regel**: Distanz > Sollwert ‚Üí vorw√§rts fahren

---

# Vision-System: Design-Entscheidungen

---

## Architektur-Entscheidungen (Vision)

### 1. Zwei separate ROS2-Nodes + ausgelagerte OpenCV-Logik

**Entscheidung**: CameraReadOut (Bilderfassung) und ImageProcessing (Verarbeitung) als getrennte ROS2-Nodes, mit OpenCV-Logik in separate AMD-Klasse ausgelagert

**Begr√ºndung**:
- **Skalierbarkeit**: Verarbeitungsteil kann auf anderem Rechner ausgef√ºhrt werden
- **Parallelisierung**: Bilderfassung und Verarbeitung laufen asynchron
- **Code-Trennung**: OpenCV-Logik (AMD) ist unabh√§ngig von ROS2, wiederverwendbar in anderen Kontexten
- **Wartbarkeit**: Getrennte Zust√§ndigkeiten (Single Responsibility Principle)
- **Fehlertoleranz**: Ausfall eines Nodes beeinflusst den anderen nicht direkt


---

### 2. Grayscale-Konvertierung in CameraReadOut

**Entscheidung**: RGB ‚Üí Grayscale im CameraReadOut-Node, nicht im ImageProcessing

**Begr√ºndung**:

| Aspekt | Benefit |
|---|---|
| **Bandbreite** | 66% weniger Daten bei √úbertragung |
| **Bildrate** | H√∂herer Durchsatz von Bildern m√∂glich (30 Hz vs. m√∂gliche Drosselung bei RGB) |
| **Speicher** | Weniger RAM-Nutzung |
| **ArUco-Detektion** | Funktioniert gleichwertig mit Grayscale (Kontraste reichen aus) |

---

### 3. Timer-Frequenz 30 Hz in CameraReadOut

**Entscheidung**: Bilderfassung mit maximaler Kamera-Frequenz (30 Hz)

**Begr√ºndung**:
- **Maximale Aktualit√§t**: Neuste verf√ºgbare Bilder f√ºr Detektion
- **Kamera-Spezifikation**: Roboter-Kamera liefert max. 30 fps
- **Echtzeit-Anforderung**: Roboter-Steuerung ben√∂tigt niedrige Latenz
- **Pufferoptimierung**: Buffer-Size=1 verhindert veraltete Frames

---

### 3.1 CAP_PROP_BUFFERSIZE = 1 in CameraReadOut

**Entscheidung**: OpenCV-Kamera-Buffer auf Gr√∂√üe 1 setzen

**Begr√ºndung**:
- **Minimale Latenz**: Nur aktuellster Frame wird gepuffert
- **Echtzeitnavigation**: Roboter reagiert auf aktuelle Sensorposition
- **Stabilit√§t**: Verhindert veraltete Frames in P-Regler

**Code**: `cap.set(cv.CAP_PROP_BUFFERSIZE, 1)`

---

## Marker-Erkennungs-Entscheidungen

### 4. ArUco-Dictionary DICT_5X5_1000

**Entscheidung**: 5√ó5-Marker mit bis zu 1000 verschiedenen IDs

**Vergleich mit Alternativen**:

| Dictionary | Marker-Gr√∂√üe | ID-Bereich | Erkennungs-Qualit√§t |
|---|---|---|---|
| **4X4_50** | 4√ó4 Bits | 0-49 | Weniger robust bei Distanz/Bewegungsunsch√§rfe |
| **5X5_1000** | 5√ó5 Bits | 0-999 | **Optimal** ‚úì |
| **6X6_250** | 6√ó6 Bits | 0-249 | Bessere Reichweite, aber weniger IDs verf√ºgbar |

**Begr√ºndung f√ºr 5X5_1000**:
- ‚úì Bessere Erkennbarkeit aus Distanz/niedriger Aufl√∂sung als 4X4
- ‚úì Ausreichend viele IDs f√ºr Mehrroboter-Szenarien (nicht begrenzt auf 2-3 Roboter)
- ‚úì Schnellere Verarbeitung als 6X6
- ‚úì Balance zwischen Robustheit und Vielfalt

---

### 5. Marker-Priorit√§ts-Logik (ID 69 > ID 0)

**Entscheidung**: Marker 69 vor Marker 0 bevorzugen (bei Mehrfach-Erkennung)

**Begr√ºndung**:
- **Performance**: Priorit√§t vor solvePnP entscheiden (spart Berechnungen)
- **Szenario**: Fokus auf anderen Roboter (ID 69) statt Objekt (ID 0)
- **Flexibilit√§t**: Leicht konfigurierbar
---


---

## Distanz- und Winkelberechnungen

### 6. solvePnP mit SOLVEPNP_IPPE_SQUARE

**Entscheidung**: Pose-Estimation via `cv.solvePnP()` mit IPPE_SQUARE-Flag

**Begr√ºndung**:
- Nutzt vorkalibrierte Kameraparameter f√ºr pr√§zise Pose
- IPPE_SQUARE spezialisiert auf quadratische, planare Marker (ArUco)
- OpenCV-Standard, etabliert und optimiert

---

### 7. Manuelle Winkelberechnung statt rvec

**Entscheidung**: Winkel via `atan2(tvec[0], tvec[2])` statt aus `rvec`

**Begr√ºndung**:
- `rvec` liefert sprunghafte Werte bei Grenzf√§llen (zu instabil f√ºr P-Regler)
- Manuelle Berechnung aus `tvec` ist mathematisch stabil und vorhersagbar
- Direkt f√ºr Regelung nutzbar (Wertebereich [-œÄ, œÄ])

**Visualisierung** (Draufsicht von oben):
```
         Kamera
          *
         /|
        / | z_distance (tvec[2])
  x_off/  |
      /   |
     -----+
    Marker
    
tan(angle) = x_offset / z_distance
angle = atan2(x_offset, z_distance)
```

**Bereich**: [-œÄ, œÄ] (alle 4 Quadranten)

---

### 8. Last-Valid-Value-Filter (3-Wert-Buffer)

**Entscheidung**: Robustheits-Filter mit 3-Wert-Schiebe-Buffer

**Begr√ºndung**: Filtert tempor√§re Fehler (Lichtwechsel, Verdeckung) aus; gibt neuesten g√ºltigen Wert zur√ºck


---

## Fehlerbehandlung-Entscheidungen

### 9. Fehlercodes (-1000.0, œÄ, 9999)

**Entscheidung**: Sentinel-Werte statt Exceptions f√ºr robuste Node-Ausf√ºhrung

**Fehlerwerte**: Distanz=-1000.0 (unm√∂glich), Winkel=œÄ (unerreichbar), ID=9999 (au√üerhalb DICT)

**Begr√ºndung**: ROS2-Nodes bleiben stabil; Logik-Module k√∂nnen Fehler erkennen und reagieren

---

### 10. Error-Counter & Schwellwert (> 10)

**Entscheidung**: Error-Flag setzen nach 10 aufeinanderfolgenden Fehlern

**Begr√ºndung**: Unterscheidet Kurzzeitfehler (Lichtwechsel) von permanenten Ausf√§llen;
---

## Kalibrierungs-Entscheidungen

### 11. CharUco statt Chess-Board f√ºr Kalibrierung

**Entscheidung**: CharUco-Kalibrierung f√ºr Kamera-Matrix

**Begr√ºndung**:
- Funktioniert mit weniger Bildern als Chess-Board
- Robuster gegen Verzerrungen und Beleuchtung
- Bessere Ecken-Erkennung ‚Üí pr√§ziserer optischer Mittelpunkt


---

# Technische Herleitungen

## 1. Quaternion zu Yaw-Konversion

### 1.1 Mathematischer Hintergrund

**Gegeben**: Quaternion q = (x, y, z, w)

**Gesucht**: Yaw-Winkel (Rotation um Z-Achse)

### 1.2 Herleitung

```
Rotation Matrix aus Quaternion:
        ‚é° 1-2(y¬≤+z¬≤)   2(xy-wz)     2(xz+wy)   ‚é§
    R = ‚é¢ 2(xy+wz)    1-2(x¬≤+z¬≤)   2(yz-wx)   ‚é•
        ‚é£ 2(xz-wy)    2(yz+wx)    1-2(x¬≤+y¬≤) ‚é¶

Yaw aus Rotation Matrix:
    yaw = atan2(R[1,0], R[0,0])
        = atan2(2(xy+wz), 1-2(y¬≤+z¬≤))

Vereinfacht (h√§ufig benutzte Formel):
    yaw = atan2(2*w*z + 2*x*y, 1 - 2*y¬≤ - 2*z¬≤)
```

---

## 2. Winkel-Wrap-Around Behandlung

### 2.1 Problem

```
Wenn Roboter von -2.9 rad zu +2.9 rad dreht:
Naiver Error: 2.9 - (-2.9) = 5.8 rad (>> œÄ)
Ist aber: nur 0.4 rad Drehung
```

### 2.2 Herleitung der L√∂sung

```
Wenn |angle_error| > œÄ:
    Es ist k√ºrzer, in die andere Richtung zu gehen
    
Beispiel:
    angle_error = 3.5 rad (200¬∞)
    Statt 200¬∞ zu drehen ‚Üí 160¬∞ in andere Richtung
    
    Mathematik:
    if angle_error > œÄ:
        angle_error -= 2œÄ  (normalisiere)
    elif angle_error < -œÄ:
        angle_error += 2œÄ  (normalisiere)
```

---

## 3. Regler-Auslegung f√ºr Multi-Modul-System

### 3.1 P-Rgler

**Struktur**:
```
Soll-Winkel ‚Üí P-Regler ‚Üí angular_velocity
    Error = Soll - Ist
    Output = -Kp * Error

Soll-Distanz ‚Üí P-Regler ‚Üí linear_velocity
    Error = Soll - Ist
    Output = -Kp * Error
```

### 3.2 Kp-Wert Auslegung

**Methode**: Empirisches Tuning (Ziegler-Nichols Light)

**Prozess**:
1. Kp = 0.5 starten (konservativ)
2. Inkrementelle Erh√∂hung (+0.1) bis Oszillation auftritt
3. Kp auf 50% der Oszillations-Kp setzen
4. Mit echtem Robot validieren

---

## 4. Odometrie-Integration

### 4.1 Datenfluss von /odom

```
ROS2 /odom Topic
‚îú‚îÄ message.pose.pose.position.x [m]
‚îú‚îÄ message.pose.pose.position.y [m]
‚îî‚îÄ message.pose.pose.orientation (Quaternion)
        ‚îî‚îÄ x, y, z, w
        
Konvertierung:
quaternion_to_yaw(x, y, z, w) ‚Üí Œ∏ [rad]

Nutzung:
- InitLogic: Erste Œ∏ speichern, dann Differenz tracken
- DriveLogic: F√ºr relative Ausrichtung nutzen
- TurnLogic: Gedrehten Winkel berechnen
```

### 4.2 Position-Tracking

**Nicht direkt genutzt** f√ºr:
- FollowLogic und DriveLogic verwenden relative Zieldistanz (von Camera)
- MainController berechnet estimated_goal_pose (6m voraus)

**Grund**: 
- Zu sensorabh√§ngig (Odometrie drift)
- Vision ist augenblicklich verf√ºgbar
- Relative Koordinaten sind robuster

---

## 5. Toleranzbereiche und Kalibrierungsergebnisse

### 5.1 ANGLE_TOLERANCE Herleitungen

**Definition**: Winkelfehler, unterhalb dem Regler abschaltet

**Formel f√ºr Minimaltoleranzen**:
```
ANGLE_TOL_MIN = (Sensor_Rauschen + Quantisierung) * 2

Beispiele:
- Camera Aufl√∂sung: ¬±0.05 rad (Vision-Rauschen)
- Quaternion Genauigkeit: ¬±0.01 rad
- Sicherheitsmargin: 2√ó
‚îú‚îÄ InitLogic: 0.1 rad (minimal)
‚îú‚îÄ DriveLogic: 0.15 rad (gr√∂√üer wegen Fahrt)
‚îú‚îÄ TurnLogic: 0.1 rad (pr√§zise Rotation)
‚îî‚îÄ FollowLogic: 0.2 rad (toleranter)
```

### 5.2 GOAL_DISTANCE Herleitungen

**Definition**: Entfernung, die als "Ziel erreicht" z√§hlt
                    |
                    ‚îî‚îÄ> vom Benutzer frei w√§hlbar

**Faktoren**:
- Kollisionsfreiraum: Mindestens 10cm Abstand
- Sensor-Genauigkeit: ¬±5cm

**Typische Werte**:
```
GOAL_DISTANCE = 0.3m (30cm)
‚îú‚îÄ Roboter-L√§nge: 0.2m
‚îú‚îÄ Sensor-Fehler: ¬±0.05m
‚îî‚îÄ Safety-Margin: 0.05m
```

---

## 6. Follow-Modus Trigger-Logik

### 6.1 Aruco-ID 69 Spezifikation

**Warum ID 69?**
- Eindeutige ID (nicht 0-3 f√ºr andere Zwecke)
- Leicht zu merken (Standard-Wert)
- Dezimal: 69, Hex: 0x45

**Trigger-Logik im MainController**:
```python
if _dominant_aruco_id == 69:
    _goToFollow = True
    # Wird beim n√§chsten DRIVE‚ÜíFOLLOW √úbergang genutzt
```

**Flow**:
```
DRIVE State
  ‚îî‚îÄ Camera erkennt Marker mit ID=69
     ‚îî‚îÄ setArucoData(69) aufgerufen
        ‚îî‚îÄ MainController setzt _goToFollow=True
           ‚îî‚îÄ Beim n√§chsten Erfolg: DRIVE‚ÜíFOLLOW
```

---

## 7. Validierungs- und Teststrategien

### 7.1 Integrations-Tests

```
Test: Init ‚Üí Drive ‚Üí Turn ‚Üí Success
1. MainController initialisieren
2. Goal setzen
3. Sensordaten simulieren
4. State-√úberg√§nge √ºberpr√ºfen
5. Final-Output validieren
```

### 7.2 Field-Tests

- Verschiedene Lichtverh√§ltnisse
- Verschiedene Boden-Beschaffenheit
- Verschiedene Zielentfernungen

---

# Lessons Learned
## 1. Python Logic (Init, Drive, Turn, Follow)


### 1.1 Interface-Design 
Vorteile der einheitlichen Schnittstelle:

- Alle Module implementieren identische Methoden (getOut(), setActive(), state_machine())
- Konsistente API erleichtert Verst√§ndnis und Wartung
- MainController kann Module austauschen ohne Code-√Ñnderungen
- Neue Module in 2-4 Stunden implementierbar durch vorgegebene Struktur
- Klare Trennung von Input/Output √ºber standardisierte Datenklassen

#### Lesson Learned:  
Investition in durchdachte Interfaces zu Projektbeginn erm√∂glicht schnelle Erweiterungen w√§hrend der gesamten Entwicklung

### 1.2 Unit-Test
Schnelle Fehlererkennung durch automatisierte Tests  
Vorteile:

- Sofortige R√ºckmeldung bei Funktions√§nderungen
- Fehler werden vor Integration in Gesamtsystem erkannt
- Refactoring ohne Angst vor unerkannten Nebenwirkungen
- Module k√∂nnen isoliert ohne ROS2-Umgebung getestet werden
- Jeder State-√úbergang systematisch validierbar
- Dokumentation des erwarteten Verhaltens durch Tests

#### Lesson Learned:  
Unit-Tests als Sicherheitsnetz erm√∂glichen schnelle Iteration und verhindern zeitraubende Debugging-Sessions auf dem Roboter

### 1.3 Modulare Aufgabentrennung
Separate Module f√ºr Init, Drive, Turn, Follow  
Vorteile der Trennung:

- Jedes Modul hat klar definierte Verantwortung
- √Ñnderungen in einem Modul beeinflussen andere nicht
- Bugs sind leicht zu lokalisieren
- Neue Verhaltensweisen einzelner module einfach implementierbar
- Neue Module leicht hinzuf√ºgbar
- Wiederverwendbarkeit einzelner Module in anderen Projekten

#### Lesson Learned:  
Klare Aufgabentrennung beschleunigt Entwicklung, Debugging und Erweiterung erheblich

### 1.4 Weitere-Erkentnisse
#### Config-File (config.py):  
- Zentrale Parameter-Verwaltung erm√∂glicht schnelles Tuning ohne Code-√Ñnderung
- Experimente in "Minuten" statt "Stunden"
#### Gemeinsame Funktionen (general_funcs.py):  
- Vermeidung von Code-Duplikation
- Konsistentes Verhalten √ºber alle Module
#### State Machine Pattern:  
- Vorhersagbares und nachvollziehbares Verhalten
- Einfaches Debugging durch klare Zustandsverfolgung
- Systematische Testabdeckung aller √úberg√§nge


## 2. Camera & ArUco-Tracking

### 2.1 Custom Marker sind zu aufwendig - Standard ArUco ist deutlich besser
Anf√§ngliche Idee: Eigene Marker zur Position- und Distanz-Verfolgung entwickeln

**Problem**:
- Insgesamt sehr zeitaufwendig und fehleranf√§llig

**L√∂sung**: OpenCV DICT_5X5_1000 ArUco-Marker verwenden
- Sofort einsatzbereit, dokumentiert und getestet
- Robuste Erkennung, einfache Implementierung

#### Lesson Learned:  
**Standard-L√∂sungen bevorzugen**: Bew√§hrte Marker sparen Wochen an Entwicklungszeit gegen√ºber Custom-Implementierungen

---

### 2.2 Kreis-Erkennung funktioniert nicht im Rohr
Versuch: HoughCircles f√ºr Rohr-Tracking

**Problem**:
- Rohr ist mit einem Brett ausgelegt ‚Üí Halbkreis statt Kreis
- Keine zuverl√§ssige Verfolgung m√∂glich

#### Lesson Learned:  
**Feature-Geometrie muss zur Umgebung passen**: Generische Formen (Kreise) funktionieren nicht in nicht eindeutigen Szenarien ‚Äî eindeutig markierte Positionen (ArUco) sind robust

---

### 2.3 solvePnP rvec-Werte sind zu instabil f√ºr die Regelung
Anf√§ngliche Idee: Rotationsvektor direkt f√ºr P-Regler nutzen

**Beobachtung**: rvec springt zwischen L√∂sungen ‚Üí keine stabilen Steuerwerte

**L√∂sung**: Manuelle Berechnung aus tvec: `angle = atan2(tvec[0], tvec[2])`
- Mathematisch stabil und monoton
- Direkt verwendbar f√ºr P-Regler

#### Lesson Learned:  
**Physikalische Interpretation vor mathematischer**: Die X-Z-Position des Markers ist robuster als die Rotationsdarstellung ‚Äî Pose aus Translationsvektor ist praktikabler f√ºr Regelung

---

### 2.4 Kalibrierungs-Qualit√§t pr√§gt Pose-Berechnung entscheidend
Anf√§ngliches Problem: Chess-Board-Kalbrierung lieferte falschen optischen Mittelpunkt (cx, cy)

**Symptom**: Konstante Positions-Fehler ohne erkennbare Ursache

**L√∂sung**: CharUco-Kalibrierung mit 10‚Äì20 hochqualitativen Bildern
- Bessere Ecken-Detektion ‚Üí pr√§ziser optischer Mittelpunkt
- Direkter Einfluss auf solvePnP

#### Lesson Learned:  
**Kalibrierungs-Qualit√§t ist essentiel**: Falscher optischer Mittelpunkt f√ºhrt zu hartn√§ckigen systematischen Fehlern ‚Äî Zeit in saubere Kalibrierung investieren spart Tage beim Debugging

---

### 2.5 OpenCV Camera-Buffer muss auf Gr√∂√üe 1 gesetzt werden
Anf√§ngliches Problem: Standardm√§√üig gro√üe Buffer ‚Üí veraltete Frames in Echtzeit-Loop

**Symptom**: Roboter lenkt zu weit aus ‚Üí P-Regler bekommt verz√∂gerte Sensordaten

**L√∂sung**: `cap.set(cv.CAP_PROP_BUFFERSIZE, 1)`
- Nur aktuellster Frame wird gepuffert
- Minimale Latenz f√ºr Regelung

#### Lesson Learned:  
**Hardware-Puffering ist eine versteckte Latenzquelle**: Standard-OpenCV-Buffer verursachen Navigation-Instabilit√§t ‚Äî explizit auf Gr√∂√üe 1 setzen ist essentiell f√ºr Echtzeit-Systeme

---

### 2.6 Raspberry Pi Performance & Aufl√∂sungs-Optimierung

**Problem**: Raspberry Pi zu schwach f√ºr Full-HD-Bilder (1920√ó1080)
- Kamera liefert theoretisch HD-Qualit√§t
- Verarbeitung wird CPU-limitiert
- Bildrate kann nicht gehalten werden

**Experiment**: Verschiedene Aufl√∂sungen getestet


**Kritische Erkenntnisse**:
1. **Aufl√∂sungs-Reduktion**: 640√ó480 ist Standard-OpenCV-Gr√∂√üe
2. **RGB‚ÜíGrayscale**: Skaliert Performanz erheblich (3 Kan√§le ‚Üí 1 Kanal)
3. **Timing der Konvertierung**: Je fr√ºher die Konvertierung erfolgt, desto besser
   - Konvertierung im CameraReadOut spart Bandbreite
   - ImageProcessing kann dann kleinere Frames zu verarbeiten

#### Lesson Learned:
Bildauswahl muss spezifisch zu dem verwendeten System angepasst werden
- Niedrige Aufl√∂sung w√§hlen (640√ó480 statt HD)
- Grayscale fr√ºh im Pipeline konvertieren

---

## 3. ROS
### 3.1 Softwarearchitektur vor Implementierung
Bedeutung einer fr√ºhzeitig geplanten ROS-Architektur:

- Klare Aufteilung in Nodes, Topics, Services und Actions
- Gemeinsames Verst√§ndnis im Projektteam √ºber Datenfl√ºsse
- Vermeidung sp√§terer, aufwendiger Architektur√§nderungen
- Verantwortlichkeiten einzelner Komponenten klar definiert
- Grundlage f√ºr skalierbare und wartbare Systeme

#### Lesson Learned:  
Bei Frameworks ist es besonders wichtig, **vor der Implementierung eine durchdachte Softwarearchitektur zu entwerfen**, um dem Projektteam eine gemeinsame Orientierung zu geben und sp√§tere strukturelle Probleme zu vermeiden

---

### 3.2 Fr√ºhzeitige Interface-Erstellung
Vorteile einer fr√ºhzeitig definierten Schnittstellenstruktur:

- Einheitliche Message-Typen und klare Kommunikationsvertr√§ge
- Austauschbarkeit einzelner Nodes ohne Anpassung anderer Komponenten
- Reduzierte Kopplung zwischen Modulen
- Vereinfachte Teamarbeit durch klare Erwartungen an Ein- und Ausgaben
- Langfristige Stabilit√§t des Gesamtsystems

#### Lesson Learned:  
Eine **fr√ºhzeitig durchdachte Interface-Erstellung** hilft, langfristig Problemen vorzubeugen und reduziert den Wartungsaufwand erheblich

---

### 3.3 Integrationsstrategie (Big-Bang vs. Inkrementell)
Erfahrungen aus der Systemintegration:

- Big-Bang-Integrationen sind schwer planbar und fehleranf√§llig
- Fehlerursachen sind bei sp√§ter Gesamtintegration schwer zu lokalisieren
- Hoher Koordinationsaufwand im Team notwendig
- Funktioniert nur, wenn sich das gesamte Team der Risiken bewusst ist
- Kontinuierliche Gegenma√ünahmen und Tests erforderlich

#### Lesson Learned:  
**Big-Bang-Integrationen sind sehr aufwendig** und funktionieren nur dann, wenn sich das gesamte Team der Nachteile bewusst ist und aktiv gegen entstehende Probleme anarbeitet

---

### 3.4 Dokumentation & Framework-Verst√§ndnis
Bedeutung guter Dokumentation bei der Arbeit mit ROS:

- Fehlende oder unklare Dokumentation verlangsamt die Entwicklung stark
- Innovative Nutzung von Frameworks erfordert tiefes Systemverst√§ndnis
- Implizite Annahmen f√ºhren schnell zu Fehlkonfigurationen
- Eigene Dokumentation wird essenziell bei unklaren Framework-Details
- Wissenstransfer im Team ohne Dokumentation kaum m√∂glich

#### Lesson Learned:  
**Schlecht dokumentierte Frameworks f√ºhren zu gro√üen Problemen**, insbesondere dann, wenn sie innovativ oder au√üerhalb typischer Anwendungsf√§lle genutzt werden



---

## Dokumente und Referenzen

**Siehe auch**:  

Documentation:  
[logic_2.md](logic_2)  
[ros.md](ros.md)  
[config.py](../muri_logics/config.py)  

Unit-Tests:  
[test_init_logic.py](../muri_logics/muri_logics/test/test_init_logic.py)  
[test_drive_logic.py](../muri_logics/muri_logics/test/test_drive_logic.py)  
[test_turn_logic.py](../muri_logics/muri_logics/test/test_turn_logic.py)  
[test_follow_logic.py](../muri_logics/muri_logics/test/test_follow_logic.py)  

---

**Dokumentversion**: 2.0.0  
**Status**: In Review  
**N√§chste Aktualisierung**: Nach v2.0.1 Release